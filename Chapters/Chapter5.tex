% Chapter 1

\chapter{Summary and Future Work} % Main chapter title

\label{Chapter5} % For referencing the chapter elsewhere, use \ref{Chapter1} 

The results of this project are the groundwork for further investigation of the simplification of cloud environments for researchers. With cloud computing continuing to grow, it is possible to have these kinds of services, such as Nikeza, integrated with it directly in a more researcher focused effort. More cloud environments are being adopted as the go-to platform for delivering flexible scientific analysis. This is evident from projects such as the SADIRC being built from the ground up to support astronomy and bioinformatics workloads and the Cloud Infrastructure for Microbial Bioinformatics (CLIMB) system which a research cloud environment built to provide resources for microbial bioinformatics in the United Kingdom \parencite{connor2016climb}.

\section{Summary and Conclusions}

In light of the issues raised in Chapter \ref{Chapter1}, such as data growth becoming an increasingly difficult problem and technical skill being a requirement to use modern cloud computing environments, this project aimed to provide a solution. A proof-of-concept automation tool for researcher workflows, named Nikeza, was designed and prototyped. This tool provided a simpler and non-technical approach to utilising the cloud environment.

Deployment of Nikeza was done using a local private cloud environment built using OpenStack as a base, which allowed it to be compared in executing a research workflow against existing cloud environments of a similar nature, namely Amazon AWS, given the assumption that the data to be processed was already at the location. 

The results showed that using Amazon AWS for research purposes is very possible. However, this requires a detailed technical knowledge of how to utilise not only the Amazon provided web dashboard, but also the virtual machines created on it themselves. With the Amazon AWS test, the researcher is required to navigate through a maze of different dashboards which provide information on the different services that are on offer. They are required to create a virtual machine with a pre-built operating system image that provides them with the required base to begin, followed by the installation of their entire work environment. The researcher must also manually ensure that the data they wish to operate on is pulled into the virtual environment in some fashion. Once this is completed, the researcher may move their workflow to the platform in order to execute it and they are left to retrieve the data from the virtual machine and shut it down manually. The only way that this can be simplified for researchers is if the organisation they work for provides pre-built virtual machine images with the necessary work environment or tools installed, but this leads to issues of maintaining those and creating environments for every novel approach which is unmaintainable.

In comparison, the work done in the Nikeza project provided a simpler platform for researchers to perform remote computational work through a workflow language. More specifically, it looked at addressing the three key aims of 1) the moving of workflows to the cloud, 2) simplifying cloud environments for researchers, and 3) integrating workflow languages into the cloud.

\paragraph{Moving Workflows to the Cloud}
Workflow language specifications or tools allow researchers to define an instruction specification for the analysis. The fact that most provide ways of fetching tools from local or non-local sources means that the movement of this specification is very easy and portable. The tests conducted for this thesis show that these technologies compliment a cloud environment and promote a focus on research, rather than system preparation and allowed the size of the data that needed to be sent from the researcher to the remote environment to be relatively tiny.

\paragraph{Simplification of Cloud Environments}
The comparison between the Amazon cloud on its own and OpenStack cloud with Nikeza shows, when running the same workflow, that it is substantially easier to use Nikeza from a researcher perspective. All of the technical work is automated and abstracted for the researcher, allowing them to focus on what they want to accomplish. The researcher merely has to log in to the dashboard, upload their workflow script, provide the flags for the workflow, select the data and the placement of the data, and finally where the data is sent to upon completion. This is provided in one simple interface for the researcher and they are never expected to interact with the virtual environment at all. This proof-of-concept demonstrates the viability of creating easy-to-use interfaces to the cloud.

\paragraph{Integrating Workflow Languages into the Cloud}
The integration of workflow languages can be done in two ways. The way that this thesis project demonstrated it was to create a software platform that interacts with a cloud environment to utilise its functions on behalf of a user. This is a flexible and customisable approach. The other way is for cloud providers to treat workflow languages as a first-class citizen and offer their own workflow language integration directly into their platforms.

This project has successfully managed to answer all three posed research questions and has achieved the majority of the technical functionality requirements laid out for the system as mentioned in Chapter 4, section 4.6. The technical functionality aspect that was not reached was to create a fully modular system for ease of replacing plug-ins to support different cloud environments. This was not achieved due to time constraints and it being a greater task than originally envisioned. Currently, the application is very strongly tied with the OpenStack platform.

The Nikeza project has successfully demonstrated that researchers are able to analyse their data at the site where the data is being generated. It allows researchers to provide their own analysis environments and process data exactly the way that they expect, without having to rely on specific tools to be made available from the institution. It also shows that reproducible scientific workflows can fairly easily be used on top of cloud environments, taking advantage of efficient resource usage.

\section{Future Work}

During the completion of this thesis, the landscape for research analysis on the cloud has changed. It is important to note that there have been progressions by other projects into utilising the cloud in a way that this thesis project aimed to do. While not identical to this approach, projects such as Galaxy also serve to prove the usefulness of adapting the work onto scalable and distributed cloud environments. The South African Medical Research Council also announced the launch of the African Genome Center that will be a local sequencing facility. The architecture outlined in this thesis would be well suited to a sequencing facility such as the African Genome Center.

Great strides have also been made in executing workflow languages and specifications on remote cloud environments. CWL executors such as Toil have gained native ability to interact with cloud environments such as OpenStack, Amazon AWS or Google Cloud Engine (among others) with many of their unique features and have given further confirmation of the aims that are laid out in this thesis paper. This also further exemplifies the usefulness adopting cloud technologies as a base for IT infrastructure as institutions which can complement traditional HPC environments by allowing them to continue to operate, but also provide more flexible ways of compute for researchers. The Rabix Composer\footnote{\url{https://rabix.io/}} tool even offers a graphical interface, albeit slightly complex, for composing and executing CWL workflows.

As for the system implemented for this paper, Nikeza, various improvements can be made directly including, but not limited to the following.

\subsection{Ability to utilise storage container mounting}
This would prevent data from having to be copied from the storage unit in the cloud environment before processing and would reduce waiting time until processing can begin.

\subsection{Allowing Data Retrieval from the Interface}
Currently, the interface does not allow users to download data from the cloud environment through the Nikeza system. This would simplify the retrieval task for the researcher substantially as they would not have to log into the cloud environment and navigate through that interface in order to retrieve the resulting data. 

\subsection{Contextual System Knowledge}
The system could be intelligent and able to interact with the scheduler of the cloud environment in order to understand when researchers can be provided with virtual environments and when the system or their user accounts are oversubscribed. This could lead to better utilisation of resources and overall more efficient analysis execution.

\subsection{Improved Reporting}
The user could be provided with more (detailed) information about the status of their jobs. Currently, there is very little information provided about what their jobs are actually doing. The user only has an indication of whether the virtual machine that their workflows are running on is on or not.

\subsection{Improved Failure Handling}
Failures in workflow execution are currently not graceful. If a failure occurs, the virtual environment will remain active and the user would not know that the workflow has ceased. It would be incredibly useful for the user to understand where things went wrong in their analysis in order to address the problems in a timely fashion. If the system could provide detailed statistics about where things went wrong and potentially move on to other parts of the analysis that are not dependent on the failed steps it would improve productivity.

\subsection{Providing Instance Types}
Allowing users to select which types of instances they want to run their workflow on can assist the processing of different workflows greatly. Some workflows benefit greatly from multiple cores or larger internal storage capacity. Currently, only one simple instance is provided as a means to conduct the proof-of-concept.

\subsection{Supporting Multiple Container Engines}
While Docker is a very popular and mature container engine and is used by the scientific community today, the rise of alternatives like Singularity indicates that there may be a need to support more than just Docker. Options in terms of container platforms enable the researcher to have greater control over their workflow and how it is executed.

\subsection{Utilising Container Orchestration Tools}
Various cloud environments support different container platforms. For example, Google has its Container Engine and OpenStack has Magnum. Utilising these environments can allow distributed, scalable and parallel workflows to be executed in a simpler manner.

\subsection{Integration of Nikeza-like dashboards into Existing Clouds}
It is also possible to go the integrated route. Cloud providers could adopt their own researcher-friendly dashboard alternatives to their standard cloud interface. For OpenStack, this could be as simple as a single or group of developers writing a module for it and asking for it to be included as an official OpenStack component, given its open source nature.

The proof-of-concept software developed for this thesis, dubbed Nikeza, provides a starting point to improving the ease of use of cloud computing resources for non-technical researchers. It also encourages the implementation of more local private cloud computing resources across Africa in an attempt to scale bioinformatics analyses.
